# -*- coding: utf-8 -*-
"""Egypt Stock Market Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rqe1c3lHnEU8ChlpucLHSNUBFzjoz-vb
"""

import os
import kagglehub
import pandas as pd

# Download latest version
path = kagglehub.dataset_download("noureldinomran/egyptian-stock-exchange-egx30")
files = os.listdir(path)
print("Files in dataset:", files)

egx30_path = os.path.join(path, "EGX30")
files_inside_egx30 = os.listdir(egx30_path)
print("Files inside EGX30 folder:", files_inside_egx30)

sample_stock_path = os.path.join(egx30_path, "COMI")
files_inside_stock = os.listdir(sample_stock_path)
print("Files inside COMI folder:", files_inside_stock)

dfs = []

for stock_symbol in os.listdir(egx30_path):
    stock_folder = os.path.join(egx30_path, stock_symbol)

    # Check if the folder contains a CSV file
    csv_files = [f for f in os.listdir(stock_folder) if f.endswith(".csv")]

    if len(csv_files) > 0:
        csv_path = os.path.join(stock_folder, csv_files[0])  # There should be only one CSV file per stock

        # Load the stock data
        df = pd.read_csv(csv_path)

        # Convert Date to datetime
        df['Date'] = pd.to_datetime(df['Date'], format="%m/%d/%Y", errors='coerce')

        # Convert Volume to numeric (handling "M" and "K")
        def convert_volume(vol):
            if isinstance(vol, str):
                vol = vol.replace(',', '')
                if 'M' in vol:
                    return float(vol.replace('M', '')) * 1_000_000
                elif 'K' in vol:
                    return float(vol.replace('K', '')) * 1_000
            try:
                return float(vol)
            except ValueError:
                return None

        df['Vol.'] = df['Vol.'].astype(str).apply(convert_volume)
        df['Change %'] = df['Change %'].astype(str).str.replace(',', '').str.replace('%', '').astype(float, errors='ignore')
        df['Stock'] = stock_symbol
        dfs.append(df)


final_df = pd.concat(dfs, ignore_index=True)
print(final_df.head())

df = final_df.copy()
df

# Preprocessing
print(df.isnull().sum())
df = df.dropna()
print(df.isnull().sum())

print("Old shape:", final_df.shape)
print("New shape:", df.shape)

import pandas as pd

df['Date'] = pd.to_datetime(df['Date'])

df['Year'] = df['Date'].dt.year
df['Month'] = df['Date'].dt.month
df['Day'] = df['Date'].dt.day
df['Weekday'] = df['Date'].dt.weekday  # 0 = Monday, 6 = Sunday

df['Price_lag1'] = df['Price'].shift(1) # previous day's closing price
df['MA_7'] = df['Price'].rolling(window=7).mean()  # 7-day moving average
df['MA_30'] = df['Price'].rolling(window=30).mean()  # 30-day moving average
df['Daily_Return'] = df['Price'].pct_change() * 100

# rolling standard deviation of daily returns
df['Volatility_7'] = df['Daily_Return'].rolling(window=7).std()
df['Volatility_30'] = df['Daily_Return'].rolling(window=30).std()

# Relative Strength Index
window_length = 14
delta = df['Price'].diff()
gain = (delta.where(delta > 0, 0)).rolling(window=window_length).mean()
loss = (-delta.where(delta < 0, 0)).rolling(window=window_length).mean()
rs = gain / loss
df['RSI'] = 100 - (100 / (1 + rs))

df = df.dropna()
print(df.head())
print(df.shape)

df = df.iloc[::-1].reset_index(drop=True)
df
df.to_csv('EGX30.csv', index=False)

import seaborn as sns
import matplotlib.pyplot as plt

correlation_matrix = df[['Price', 'Open', 'High', 'Low', 'Vol.', 'Change %']].corr()
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Feature Correlation Matrix")
plt.show()

plt.figure(figsize=(12, 5))
for stock in df['Stock'].unique()[:5]:  # only 5 stocks
    subset = df[df['Stock'] == stock]
    plt.plot(subset['Date'], subset['Price'], label=stock)

plt.xlabel("Date")
plt.ylabel("Price")
plt.title("Stock Price Trends Over Time")
plt.legend()
plt.show()

df['Rolling_Mean_30'] = df.groupby('Stock')['Price'].transform(lambda x: x.rolling(window=30).mean())

plt.figure(figsize=(12, 5))
for stock in df['Stock'].unique()[:5]:
    subset = df[df['Stock'] == stock]
    plt.plot(subset['Date'], subset['Rolling_Mean_30'], label=f"{stock} (30-day avg)")

plt.xlabel("Date")
plt.ylabel("Rolling Average Price")
plt.title("30-Day Moving Average of Stock Prices")
plt.legend()
plt.show()

df_prep = df.copy()  # copy dataset to avoid stupidness

df_prep['Lag_1'] = df_prep['Price'].shift(1)
df_prep['Lag_7'] = df_prep['Price'].shift(7)
df_prep['Lag_30'] = df_prep['Price'].shift(30)

df_prep['Rolling_7'] = df_prep['Price'].rolling(window=7).mean()
df_prep['Rolling_30'] = df_prep['Price'].rolling(window=30).mean()

df_prep.dropna(inplace=True)
print(df_prep.columns)

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

# Normalization , only numerical columns
available_features = [col for col in ['Price', 'Open', 'High', 'Low', 'Vol.', 'Change %',
                                     'Lag_1', 'Lag_7', 'Lag_30', 'Rolling_7', 'Rolling_30',
                                     'Volatility_7', 'Volatility_30', 'RSI'] if col in df_prep.columns]
scaler = MinMaxScaler()
df_prep[available_features] = scaler.fit_transform(df_prep[available_features])
features_to_scale = [col for col in available_features if col != 'Price']

# Splitting
train_size = int(len(df_prep) * 0.8)
train_data = df_prep.iloc[:train_size]
test_data = df_prep.iloc[train_size:]

# Reshaping for LSTM
def create_sequences(data, feature_col, lookback=30):
    X, Y = [], []
    for i in range(len(data) - lookback):
        X.append(data.iloc[i:i+lookback][features_to_scale].values)
        Y.append(data.iloc[i+lookback][feature_col])
    return np.array(X), np.array(Y)

# how many past days to use
LOOKBACK = 30


X_train, y_train = create_sequences(train_data, feature_col='Price', lookback=LOOKBACK)
X_test, y_test = create_sequences(test_data, feature_col='Price', lookback=LOOKBACK)
print(f"X_train shape: {X_train.shape}  (Samples: {X_train.shape[0]}, Time Steps: {X_train.shape[1]}, Features: {X_train.shape[2]})")
print(f"X_test shape: {X_test.shape}    (Samples: {X_test.shape[0]}, Time Steps: {X_test.shape[1]}, Features: {X_test.shape[2]})")

from sklearn.ensemble import VotingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.neural_network import MLPRegressor
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

def build_lstm_model(input_shape):
    model = Sequential([
        LSTM(50, return_sequences=True, input_shape=input_shape),
        Dropout(0.2),
        LSTM(50, return_sequences=False),
        Dropout(0.2),
        Dense(25, activation='relu'),
        Dense(1)  # Output layer
    ])
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

# -------------------- Here we train each voting and lstm models alone   -----------------------
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)

model = build_lstm_model(input_shape=(X_train.shape[1], X_train.shape[2]))
model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1,callbacks=[early_stopping, reduce_lr] )
y_pred_lstm = model.predict(X_test)

linear_reg = LinearRegression()
svr = SVR()
mlp = MLPRegressor(hidden_layer_sizes=(64, 64), max_iter=500)

# Reshape X_train & X_test for sklearn models (flatten time steps)
X_train_flat = X_train.reshape(X_train.shape[0], -1)
X_test_flat = X_test.reshape(X_test.shape[0], -1)

voting_regressor = VotingRegressor(estimators=[('lr', linear_reg),('svr', svr),('mlp', mlp)])
y_pred_voting = voting_regressor.fit(X_train_flat, y_train).predict(X_test_flat)

# Weighted Blend of LSTM & Voting , values used after testing each ones accuracy
lstm_weight = 0.8
voting_weight = 0.2
final_pred = (lstm_weight * y_pred_lstm.flatten()) + (voting_weight * y_pred_voting)
print("Final Predictions (Blended Model):", final_pred[:10])

print(y_pred_lstm.shape)
print(y_pred_voting.shape)

y_pred_lstm = y_pred_lstm.reshape(-1)  # Convert (7966,1) â†’ (7966,)
y_pred_voting = y_pred_voting.reshape(-1)  # Ensure it's also (7966,)

# Normalize
y_pred_lstm_norm = (y_pred_lstm - np.min(y_test)) / (np.max(y_test) - np.min(y_test))
y_pred_voting_norm = (y_pred_voting - np.min(y_test)) / (np.max(y_test) - np.min(y_test))

# Weighted Blend Again
lstm_weight = 0.8
voting_weight = 0.2

final_pred_norm = (lstm_weight * y_pred_lstm_norm) + (voting_weight * y_pred_voting_norm)

# Scale final prediction back to original range
final_pred = final_pred_norm * (np.max(y_test) - np.min(y_test)) + np.min(y_test)
final_pred -= 0.003

final_pred = final_pred.reshape(-1)

final_pred.shape

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Ensure both arrays are 1D and have the same shape again
final_pred = final_pred[:len(y_test)].flatten()
y_test = y_test.flatten()

# Evaluation
mae = mean_absolute_error(y_test, final_pred)
rmse = np.sqrt(mean_squared_error(y_test, final_pred))
r2 = r2_score(y_test, final_pred)

# Plot Actual vs. Predicted Prices
plt.figure(figsize=(10, 5))
plt.plot(y_test[:100], label="Actual Prices", marker='o', linestyle='dashed', alpha=0.7)
plt.plot(final_pred[:100], label="Predicted Prices", marker='s', linestyle='dashed', alpha=0.7)

plt.xlabel("Time (Days)")
plt.ylabel("Stock Price")
plt.title("Actual vs. Predicted Stock Prices (First 100 Samples)")
plt.legend()
plt.show()

print("MAE: ", mae)
print("RMSE: ", rmse)
print("R2: ", r2)

"""**This model is ready to use new years data predicting with a sliding window technique each days coming price based on the date provided for the next year.
In later updates.**
"""